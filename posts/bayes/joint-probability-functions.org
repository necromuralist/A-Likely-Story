#+BEGIN_COMMENT
.. title: Joint Probability Functions
.. slug: joint-probability-functions
.. date: 2019-06-12 12:33:59 UTC-07:00
.. tags: bayes,probability
.. category: Bayes' Rule
.. link: 
.. description: Looking at Joint Probability Functions.
.. type: text
.. status: 
.. updated: 

#+END_COMMENT
#+OPTIONS: ^:{}
#+OPTIONS: H:5
#+TOC: headlines 2
#+BEGIN_SRC ipython :session joint :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Beginning
  This looks at the case where we have more than one input and more than one possible output value. This assumes the possible outputs are discrete. 
** Imports
*** Python
#+begin_src ipython :session joint :results none
from argparse import Namespace
from functools import partial
from pathlib import Path
#+end_src
*** PyPi
#+begin_src ipython :session joint :results none
from bokeh.models import HoverTool
import holoviews
import pandas
#+end_src
*** My Stuff
#+begin_src ipython :session joint :results none
from graeae.visualization import EmbedHoloview
#+end_src
** The Plotting
*** The Holoviews Embedder
#+begin_src ipython :session joint :results none
SLUG = "joint-probability-functions"
output = Path("../../files/posts/bayes/")/SLUG
holoviews.extension("bokeh")
Embed = partial(EmbedHoloview, folder_path = output)
#+end_src

*** The Plot Settings
#+begin_src ipython :session joint :results none
Plot = Namespace(
    width=800,
    height=800,
)
#+end_src
* Middle
** The Joint Probability Function
The *Joint Probability Function* is the distribution of input and output probabilities for each joint probability. To find the probabilities we need to take measurement counts. If we had two types of data and three hypotheses we could write out our counts in a table like this.

| Data  | $\theta_1$ | $\theta_2$ | $\theta_3$ | Sum |
|-------+------------+------------+------------+-----|
| $x_1$ |          2 |          0 |          1 |   3 |
| $x_2$ |          1 |          4 |          2 |   7 |
|-------+------------+------------+------------+-----|
| Sum   |          3 |          4 |          3 |  10 |

The intersection of data and hypothesis is the count we got for our joint probability calculation. To get the actual joint probability we divide the numbers by the total count.

| Data  | $\theta_1$ | $\theta_2$ | $\theta_3$ | Sum |
|-------+------------+------------+------------+-----|
| $x_1$ |        0.2 |          0 |        0.1 | 0.3 |
| $x_2$ |        0.1 |        0.4 |        0.2 | 0.7 |
|-------+------------+------------+------------+-----|
| Sum   |        0.3 |        0.4 |        0.3 |   1 |

So, for instance, the joint probability $p(x_2, \theta_2)$ is 0.1. The summary values at the bottom are the /marginal likelihood of the hypotheses/ - $p(\theta_2) = 0.4$ - and the summary values on the far right are the /marginal likelihood of the data/ - $p(x_2) = 0.7$.

** Visualizing It
#+begin_src ipython :session joint :results none
data = pandas.DataFrame([
    [2, 1, 1],
    [0, 4, 2],
    [1, 2, 3]
], columns=["x_1", "x_2", "theta"])
#+end_src

#+begin_src ipython :session joint :results output raw :exports both

scattered = holoviews.Scatter(data, vdims=["x_1"], kdims=["theta"]).opts(
    jitter=0.1,
    size=holoviews.dim("x_1")*10 + 5,
).opts(
    padding=0.5,
    height=Plot.height - 200,
    width=Plot.width,
    tools=["hover"],
)
bar = holoviews.Bars(data, "theta")
plot = (scattered + bar).opts(title="Theta vs x1")
Embed(plot=plot, file_name="theta_vs_x1_toy")()
#+end_src

#+RESULTS:
#+begin_export html
<object type="text/html" data="theta_vs_x1_toy.html" style="width:100%" height=800>
  <p>Figure Missing</p>
</object>
#+end_export
* End
** Source
1. Stone JV. Bayesâ€™ rule: a tutorial introduction to Bayesian analysis. First edition, third printing [with corrections]. Sheffield: Sebtel Press; 2014. 170 p. 
